name: Run unit tests on GPUs
on:
  push:
    branches:
      - master

concurrency:
  cancel-in-progress: true
  group: gpu-tests-${{ github.ref_name }}-${{ !(github.ref_protected) || github.sha}}
jobs:
  gpu-tests:
    env:
      DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.4
      PR_NUMBER: ${{ github.event.pull_request.number }}
      REPOSITORY: ${{ github.repository }}
    runs-on: linux.8xlarge.nvidia.gpu
    steps:
      - name: Start Energy Measurement
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          task: start-measurement
      - name: Clean workspace
        run: 'echo "::group::Cleanup debug output"

          sudo rm -rfv "${GITHUB_WORKSPACE}"

          mkdir -p "${GITHUB_WORKSPACE}"

          echo "::endgroup::"

          '
      - id: measurement-2
        name: Record Measurement After Clean workspace
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Clean workspace
          task: get-measurement
      - name: Checkout repository (pytorch/test-infra)
        uses: actions/checkout@v4
        with:
          path: test-infra
          repository: pytorch/test-infra
      - name: Setup Linux
        uses: ./test-infra/.github/actions/setup-linux
      - name: Pull docker image
        uses: ./test-infra/.github/actions/pull-docker-image
        with:
          docker-image: ${{ env.DOCKER_IMAGE }}
      - name: Checkout repository (${{ github.repository }})
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          path: ${{ github.repository }}
          ref: ${{ github.ref }}
          repository: ${{ github.repository }}
      - name: Start Pytorch container
        run:
          "docker run --name pthd --gpus=all --rm \\\n  --cap-add=SYS_PTRACE \\\
          \n  --detach \\\n  --ipc=host \\\n  --security-opt seccomp=unconfined \\\
          \n  --shm-size=2g \\\n  --tty \\\n  --ulimit stack=10485760:83886080 \\\n\
          \  -v $PWD:/work \\\n  -w /work \\\n  ${DOCKER_IMAGE}\n\nscript=$(cat <<\
          \ EOF\n\n  set -xe\n\n  nvidia-smi\n  ls -alh\n\n  conda --version\n  python\
          \ --version\n\nEOF\n)\ndocker exec -t pthd /bin/bash -c \"${script}\"\n"
        working-directory: ${{ github.repository }}
      - id: measurement-8
        name: Record Measurement After Start Pytorch container
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Start Pytorch container
          task: get-measurement
      - name: Install PyTorch and dependencies
        continue-on-error: false
        run: |

          script=$(cat << EOF

          set -xe

          # Install PyTorch
          if [ "${{ matrix.pytorch-channel }}" == "pytorch" ]; then
            pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu124
          else
            pip install --upgrade --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu124
          fi

          python -c "import torch; print(torch.__version__, ', CUDA is available: ', torch.cuda.is_available()); exit(not torch.cuda.is_available())"
          pip list

          # Install dependencies
          pip install -r requirements-dev.txt
          pip install -e .

          EOF
          )

          docker exec -t pthd /bin/bash -c "${script}"
      - id: measurement-10
        name: Record Measurement After Install PyTorch and dependencies
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Install PyTorch and dependencies
          task: get-measurement
      - continue-on-error: false
        name: Run GPU Unit Tests
        uses: nick-fields/retry@v2.9.0
        with:
          command:
            docker exec -t pthd /bin/bash -xec 'bash tests/run_gpu_tests.sh
            2'
          max_attempts: 5
          new_command_on_retry:
            docker exec -e USE_LAST_FAILED=1 -t pthd /bin/bash
            -xec 'bash tests/run_gpu_tests.sh 2'
          shell: bash
          timeout_minutes: 45
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          fail_ci_if_error: false
          file: ${{ github.repository }}/coverage.xml
          flags: gpu-2
      - continue-on-error: false
        name: Run examples in container
        run: 'script=$(cat << EOF


          set -xe


          # Install additional example dependencies

          pip install fire


          # Check training on cifar10, run without backend

          ## initial run

          CI=1 python examples/cifar10/main.py run --checkpoint_every=200 --stop_iteration=500

          ## resume

          CI=1 python examples/cifar10/main.py run --checkpoint_every=200 --num_epochs=7
          --resume-from=/tmp/output-cifar10/resnet18_backend-None-1_stop-on-500/training_checkpoint_400.pt


          # Check training on cifar10, run with NCCL backend using torchrun

          ## initial run

          CI=1 torchrun --nproc_per_node=2 examples/cifar10/main.py run --backend=nccl
          --checkpoint_every=200 --stop_iteration=500

          ## resume

          CI=1 torchrun --nproc_per_node=2 examples/cifar10/main.py run --backend=nccl
          --checkpoint_every=200 --num_epochs=7 --resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt


          # Check training on cifar10, run with NCCL backend using spawn

          ## initial run

          CI=1 python -u examples/cifar10/main.py run --backend=nccl --nproc_per_node=2
          --checkpoint_every=200 --stop_iteration=500

          ## resume

          CI=1 python -u examples/cifar10/main.py run --backend=nccl --nproc_per_node=2
          --checkpoint_every=200 --num_epochs=7 --resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt


          EOF

          )


          docker exec -t pthd /bin/bash -c "${script}"

          '
      - id: measurement-14
        name: Record Measurement After Run examples in container
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Run examples in container
          task: get-measurement
      - if: ${{ always() }}
        name: Teardown Linux
        uses: ./test-infra/.github/actions/teardown-linux
      - id: display-measurement
        name: Display Energy Results
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          task: display-results
      - name: Save Total Energy Consumption Data
        run: echo '${ steps.final-measurement.outputs.data-total-json }' > total_energy_consumption-1740223535.json
      - name: Upload Energy Consumption Artifact
        uses: actions/upload-artifact@v4
        with:
          name: total-energy-consumption
          path: total_energy_consumption-1740223535.json
    strategy:
      fail-fast: false
      matrix:
        pytorch-channel:
          - pytorch
          - pytorch-nightly
    timeout-minutes: 85
